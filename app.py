# -*- coding: utf-8 -*-
"""LOAN APPROVAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cGnknojN0S6kMRaoip1p-WDvAZvMnOl6

# **Selecci√≥n de DataSet**

**Descripci√≥n del Dataset:** Este dataset con un tama√±o de 10.000 filas y 14 columnas contiene informaci√≥n sobre clientes de una entidad financiera.

**Objetivo:** El problema de clasificaci√≥n a resolver es predecir la variable "Exited" (1: el cliente se di√≥ de baja, 0: el cliente permaneci√≥). Esto permite a la empresa tomar decisiones basadas en el riesgo de p√©rdida de clientes.

**Variables:**

*   RowNumber: √çndice de cada fila (irrelevante para el an√°lisis).
*   CustomerId: Identificaci√≥n √∫nica del cliente (tambi√©n irrelevante para el an√°lisis).
*   Surname: Apellido del cliente (irrelevante como predictor).
*   CreditScore: Puntaje de cr√©dito del cliente (num√©rica).
*   Geography: Pa√≠s o regi√≥n donde reside el cliente (categ√≥rica).
*   Gender: G√©nero del cliente (categ√≥rica: "Male" o "Female").
*   Age: Edad del cliente (num√©rica).
*   Tenure: Tiempo de permanencia del cliente con la entidad, en a√±os (num√©rica).
*   Balance: Saldo actual en la cuenta bancaria del cliente (num√©rica).
*   NumOfProducts: N√∫mero de productos contratados por el cliente (num√©rica).
*   HasCrCard: Indica si el cliente posee tarjeta de cr√©dito (binaria: 1 o 0).
*   IsActiveMember: Indica si el cliente es un miembro activo (binaria: 1 o 0).
*   EstimatedSalary: Salario estimado del cliente (num√©rica).
*   Exited: Variable objetivo que indica si el cliente abandon√≥ el servicio (binaria: 1 o 0).

#**0. Preparacion del Entorno**

**Descarga del dataset**
"""

import pandas as pd

def load_data():
    url = "https://raw.githubusercontent.com/dsrscientist/DSData/master/loan_prediction.csv"
    df = pd.read_csv(url)
    return df
df = load_data()

"""# **1. Analisis Exploratorio**

##**1.1. Mostramos en pantalla el dataframe (df)**
"""

df.head()

"""* Loan_ID: Identificador √∫nico para cada solicitud de pr√©stamo. (Variable irrelevante para el modelo)
* Gender: G√©nero del solicitante.
* Married: Estado civil del solicitante.
* Dependents: N√∫mero de personas a cargo del solicitante.
* Education: Nivel educativo del solicitante.
* Self_Employed: Indica si el solicitante trabaja por cuenta propia.
* ApplicantIncome: Ingreso mensual del solicitante en unidades monetarias.
* CoapplicantIncome: Ingreso mensual de un co-solicitante (por ejemplo, c√≥nyuge).
* LoanAmount: Monto solicitado del pr√©stamo en miles de unidades monetarias.
* Loan_Amount_Term: Duraci√≥n del pr√©stamo en d√≠as
* Credit_History: Registro crediticio del solicitante. (1 indica buen historial, 0 indica mal historial).
* Property_Area: Ubicaci√≥n de la propiedad relacionada con el pr√©stamo.
* Loan_Status: Variable objetivo del modelo.
"""

df = df.drop(columns= ['Loan_ID'])

# Convertimos 'Y' a 1 y 'N' a 0 en la variable objetivo Loan_Status
df['Loan_Status'] = df['Loan_Status'].map({'N': 0, 'Y': 1})

"""## **1.2. Valores nulos y Estadisticos descriptivos**"""

print("Tama√±o df:\n", df.shape)

print("Columnas del df:\n", df.columns)

"""**Valores nulos**"""

# Mostramos por pantalla el tipo de dato por variable y cantidad de nulos
df.info()

"""Podemos ver que hay nulos en la mayor√≠a de variables"""

df.isna().sum()

"""Dado que el dataset tiene 614 filas, la cantidad de valores nulos en algunas columnas no es excesiva. Por tanto, la cantidad de NaNs no justifica tratar los nulos en funci√≥n de la moda/mediana seg√∫n su rango de ingresos. Por lo que rellenar con moda o mediana global es la mejor opci√≥n para mantener el balance de los datos."""

df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)
df['Married'].fillna(df['Married'].mode()[0], inplace=True)
df['Dependents'].fillna(df['Dependents'].mode()[0], inplace=True)
df['Self_Employed'].fillna(df['Self_Employed'].mode()[0], inplace=True)
df['LoanAmount'].fillna(df['LoanAmount'].median(), inplace=True)
df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].median(), inplace=True)
df['Credit_History'].fillna(df['Credit_History'].mode()[0], inplace=True)

"""**Estadisticos descriptivos**"""

# Mostramos en pantalla los estadisticos descriptivos de las variables numericas
df[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']].describe()

"""Podemos hacer un analisis inicial sobre el conjunto con el que estamos trabajando:

* La media de ingresos del solicitante es 5403 y la del co-solicitante es 1621, lo que indica que en muchos casos el segundo ingreso es significativamente menor o incluso cero (percentil 25 de CoapplicantIncome es 0).
La desviaci√≥n est√°ndar es alta (6109 y 2926), lo que sugiere que los ingresos var√≠an considerablemente entre los solicitantes.


* La media del pr√©stamo es 146k, con una mediana de 128k, lo que indica una distribuci√≥n sesgada hacia pr√©stamos m√°s grandes.
Hay una gran dispersi√≥n en los valores, con algunos pr√©stamos alcanzando los 700k.

* La mediana de la duraci√≥n del pr√©stamo es 360 d√≠as, lo que sugiere que la mayor√≠a de los pr√©stamos se otorgan a largo plazo.

**Conclusiones iniciales:**

Hayn un riesgo de sesgo ya que, la gran variabilidad en los ingresos y cantidades de pr√©stamos puede afectar la predicci√≥n del modelo si no se normalizan correctamente.

Luego, hay valores at√≠picos en los pr√©stamos porque hay valores extremadamente grandes en comparaci√≥n con la mediana, lo que podr√≠a afectar el desempe√±o del modelo.
"""

# Mostramos en pantalla los estadisticos descriptivos de las variables categoricas
df[['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area', 'Loan_Status']].describe()

"""El dataset tiene un sesgo hacia hombres, casados y graduados, lo que podr√≠a afectar el rendimiento del modelo si no se balancean los datos.

La tasa de aprobaci√≥n es relativamente alta (68%), lo que podr√≠a significar que el modelo necesita m√°s diferenciaci√≥n entre aprobados y rechazados.

En conclusi√≥n, es posible que necesitemos aplicar t√©cnicas de undersampling.

## **1.3. Analisis de Outliers**

**Histograma**
"""

#Importamos librerias
import matplotlib.pyplot as plt
import seaborn as sns

# Seleccionamos las columnas num√©ricas excluyendo las variables binarias
numerical_columns = [
    col for col in df.select_dtypes(include=['int64', 'float64'])
    if not (df[col].nunique() == 2 and sorted(df[col].unique()) == [0, 1])
]

# Graficamos histogramas de las variables
df[numerical_columns].hist(bins=20, figsize=(15, 12))
plt.suptitle('Histogramas de Variables Num√©ricas')
plt.show()

"""Tanto ApplicantIncome como CoapplicantIncome tienen una distribuci√≥n altamente sesgada hacia la derecha.
La mayor√≠a de los ingresos son bajos, pero hay algunos valores extremadamente altos (outliers).

En cuanto al LoanAmount, la distribuci√≥n es sesgada a la derecha, indicando que la mayor√≠a de los pr√©stamos son peque√±os o medianos, pero hay algunos valores extremadamente altos (outliers).

Esto indica que hay pocos solicitantes con ingresos muy altos que piden pr√©stamos elevados, para que no afecte a la capacidad de generalizar del modelo vamos a reemplazar los valores extremos por el percentil 95.
Loan_Amount_Term (Plazo del Pr√©stamo)

Por √∫ltimo, en cuanto al plazo del pr√©stamo hay una elevada concentraci√≥n en 360 d√≠as. Este sesgo podr√≠a hacer que el modelo aprenda patrones incorrectos si la variable no tiene suficiente variabilidad.
Una posible soluci√≥n ser√≠a agruparlos en rangos para mejorar la representaci√≥n de los valores m√°s bajos (<180 d√≠as, 180-360 d√≠as, >360 d√≠as).
"""

import numpy as np
# Calculamos el percentil 95 para LoanAmount y ApplicantIncome
loan_amount_cap = df['LoanAmount'].quantile(0.90)
applicant_income_cap = df['ApplicantIncome'].quantile(0.90)
coapplicant_income_cap = df['CoapplicantIncome'].quantile(0.95)


# Reemplazamos los valores extremos
df['LoanAmount'] = np.where(df['LoanAmount'] > loan_amount_cap, loan_amount_cap, df['LoanAmount'])
df['ApplicantIncome'] = np.where(df['ApplicantIncome'] > applicant_income_cap, applicant_income_cap, df['ApplicantIncome'])
df['CoapplicantIncome'] = np.where(df['CoapplicantIncome'] > coapplicant_income_cap, coapplicant_income_cap, df['CoapplicantIncome'])

# Convertimos el plazo de pr√©stamo a variable categ√≥rica
df['Loan_Amount_Term'] = df['Loan_Amount_Term'].apply(lambda x: 0 if x <= 180 else (1 if x <= 360 else 2))

"""**Graficos de barras (variables categoricas)**


"""

# Definimos las columnas categoricas
categorical_columns = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area', 'Loan_Amount_Term', 'Loan_Status']

# Creamos un subplot con estas columnas
fig, axes = plt.subplots(nrows=1, ncols=len(categorical_columns), figsize=(25, 5))

# Creamos un bucle con las columnas para asignarles ejes
for i, col in enumerate(categorical_columns):
    sns.countplot(x=df[col], ax=axes[i])
    axes[i].set_title(f"Distribution of {col}")
    axes[i].set_xlabel(col)
    axes[i].set_ylabel("Count")

plt.tight_layout()
plt.show()

"""* G√©nero: La mayor√≠a de los solicitantes son hombres, con una menor representaci√≥n de mujeres (~112). Deber√≠amos evaluar si el g√©nero influye en la aprobaci√≥n

* Estado civil: La mayor√≠a de los solicitantes est√°n casados. Puede estar relacionado con la percepci√≥n de estabilidad financiera.
Dependents (N√∫mero de Dependientes)

* Dependientes: Casi 360 personas no tienen personas a cargo. Un menor n√∫mero de personas a cargo podr√≠a correlacionarse con una mayor capacidad de pago.

* Educaci√≥n: Casi 480 personas tienen un t√≠tulo universitario, lo que puede estar relacionado con mejores ingresos y mayor tasa de aprobaci√≥n de pr√©stamos.

* Aut√≥nomos: La mayor√≠a no son aut√≥nomos, lo que podr√≠a sugerir una mayor estabilidad financiera.

* Propiedad: Mayor concentraci√≥n en zonas semiurbanas, seguidas de urbanas y rurales.



Estado pr√©stamo: Alta tasa de aprobaci√≥n. Si el dataset tiene m√°s casos aprobados que rechazados, el modelo puede sesgarse hacia aprobar m√°s pr√©stamos.

**Conclusiones**

Por un lado, se observa un posible sesgo en g√©nero, estado civil y nivel educativo, lo que sugiere que la aprobaci√≥n de pr√©stamos puede estar influenciada por estos factores.

Por otro lado, la distribuci√≥n de personas a cargo y trabajo aut√≥nomo sugiere que ciertos grupos pueden enfrentar m√°s dificultades para obtener pr√©stamos.

Podr√≠a ser √∫til analizar la correlaci√≥n entre estas variables y la aprobaci√≥n del pr√©stamo, para determinar si el modelo deber√≠a balancear los datos o ajustar pesos.

**Boxplot**
"""

# Seleccionamos las columnas num√©ricas
numerical_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']

# Calculamos el n√∫mero de filas y columnas necesarias para los subplots
num_cols = len(numerical_columns)
num_rows = (num_cols + 1) // 2  # Redondeamos hacia arriba para m√°s de 2 columnas

# Crear subplots din√°micamente
fig, axes = plt.subplots(num_rows, 2, figsize=(12, num_rows * 5))  # 2 columnas por fila
axes = axes.flatten()  # Aplanamos para iterar f√°cilmente

# Dibujamos cada boxplot
for i, column in enumerate(numerical_columns):
    sns.boxplot(y=df[column], ax=axes[i])
    axes[i].set_title(f'Distribuci√≥n de {column}')

# Ajustamos dise√±o y eliminamos ejes vac√≠os
for j in range(i + 1, len(axes)):
    axes[j].remove()

plt.tight_layout()
plt.show()

"""## **1.4. Matriz de corelaciones**"""

# Seleccionamos las columnas num√©ricas para la matriz de correlaci√≥n
num_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']
corr_matrix = df[num_columns].corr()

# Visualizamos la matriz de correlaci√≥n con un heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('Matriz de Correlaci√≥n (Variables Num√©ricas)')
plt.show()

"""# **2. Transformamos las variables**

"""

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

X = df.drop('Loan_Status', axis=1)
y = df['Loan_Status']

numeric_features = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']
categorical_features = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area', 'Loan_Amount_Term']

# Transformamos las variables num√©ricas (imputaci√≥n + escalado)
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

# Transformamos las variables categ√≥ricas nominales (One-Hot Encoding)
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', drop= 'first'))
])

# Combinamos transformadores en ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])
model_1 = Pipeline(steps=[('preprocessor', preprocessor),
                          ('classifier', LogisticRegression(random_state=42))
                        ])
model_2 = Pipeline(steps=[('preprocessor', preprocessor),
                          ('classifier', DecisionTreeClassifier(random_state=42))
                        ])
model_3 = Pipeline(steps=[('preprocessor', preprocessor),
                          ('classifier', RandomForestClassifier(random_state=42))
                        ])
model_4 = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', SVC(kernel='rbf', C=1, probability=True, random_state=42))
])

"""#**3. Modelo clasficaci√≥n**

**Metodologia:**
Decidimos que testearemos multiples modelos de clasificacion para poder quedarnos con el mejor despues de evaluar las metricas de precision, accuracy y recall.

Dado el contexto econ√≥mico actual, priorizamos la precisi√≥n en nuestro modelo de aprobaci√≥n de pr√©stamos para minimizar el riesgo de impago y garantizar la estabilidad financiera de la entidad.

Adem√°s, utilizaremos el metodo de undersampling de RandomUnderSampler para ver si podemos mejorar el rendimiento del modelo.
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

from sklearn.metrics import accuracy_score, classification_report

# Creamos diccionario de modelos
models = {
    "Logistic Regression": model_1,
    "Decision Tree": model_2,
    "Random Forest": model_3,
    "SVC": model_4,

}

# Entrenamos y predecimos en cada modelo
for name, model in models.items():
    print(f"\n modelo: {name}")

    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

# Evaluamos cada modelo
    print(f"Accuracy: {accuracy_score(y_test, y_pred):.2f}")
    print(f"\nClassification Report:\n{classification_report(y_test, y_pred)}")

"""###**UnderSampling**"""

# Importamos la librer√≠a RandomUnderSampler
from imblearn.under_sampling import RandomUnderSampler

# Aplicamos undersampling sobre el conjunto de entrenamiento
rus = RandomUnderSampler(sampling_strategy=0.5, random_state=42)
X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)

#Verificamos que se ha hecho el undersampling correctamente
print("Distribuci√≥n despu√©s de undersampling:")
print(pd.Series(y_train_resampled).value_counts())

# Entrenamos y predecimos en cada modelo
for name, model in models.items():
    print(f"\nEntrenando modelo: {name}")

    model.fit(X_train_resampled, y_train_resampled)

    y_pred = model.predict(X_test)

# Evaluamos cada modelo
    print(f"Accuracy: {accuracy_score(y_test, y_pred):.2f}")
    print(f"\nClassification Report:\n{classification_report(y_test, y_pred)}")

"""Dado que nuestro objetivo es minimizar impagos y reducir la concesi√≥n de pr√©stamos a clientes de alto riesgo, el modelo de regresi√≥n log√≠stica es el que mejor rendimiento obtiene.

* Maximiza la precisi√≥n en clientes solventes, asegurando que las aprobaciones sean m√°s seguras.
* Reduce la probabilidad de conceder pr√©stamos a clientes que no pueden pagar (menor tasa de falsos positivos).
* Mantiene un recall alto, lo que significa que no estamos rechazando demasiados clientes solventes.

Por tanto, El modelo de LR es el m√°s adecuado para una entidad financiera que prioriza precisi√≥n y busca una cartera de pr√©stamos m√°s segura y estable.

##**4. Streamlit**
"""

#pip install streamlit

import pickle

# Guardar el modelo entrenado
with open("model.pkl", "wb") as f:
    pickle.dump(model_4, f)

import streamlit as st
import pandas as pd
import pickle

# Cargar el modelo entrenado
with open("model.pkl", "rb") as f:
    model = pickle.load(f)

# Configuraci√≥n de la app
st.title("üè¶ Loan Approval Prediction App")
st.write("Completa los detalles para predecir si el pr√©stamo ser√° aprobado.")

# Entrada de datos por el usuario
gender = st.selectbox("G√©nero", ['Male', 'Female'])
married = st.selectbox("Casado", ['No', 'Yes'])
dependents = st.selectbox("N√∫mero de personas a cargo", ['0', '1', '2', '3+'])
education = st.selectbox("Educaci√≥n", ['Not Graduate', 'Graduate'])
self_employed = st.selectbox("Trabaja por cuenta propia", ['No', 'Yes'])
applicant_income = st.number_input("Ingreso del Solicitante", min_value=0, step=100)
coapplicant_income = st.number_input("Ingreso del Co-Solicitante", min_value=0, step=100)
loan_amount = st.number_input("Cantidad del Pr√©stamo", min_value=0, step=10)
loan_term = st.selectbox("Plazo del Pr√©stamo", ['Corto Plazo (‚â§180 d√≠as)', 'Medio Plazo (181-360 d√≠as)', 'Largo Plazo (>360 d√≠as)'])
property_area = st.selectbox("Propiedad", ['Urban', 'Rural', 'Semiurban'])
# Modificar la selecci√≥n para que se entiendan las opciones de credit_history
credit_history = st.selectbox("Historial de Cr√©dito", ['Buen historial', 'Mal historial'])
# Mapeo para que el modelo reciba 1 y 0 en vez de los textos
credit_history_mapping = {'Buen historial': 1.0, 'Mal historial': 0.0}
credit_history = credit_history_mapping[credit_history]


# Mapeo de valores para que coincidan con los datos originales
dependents_mapping = {'0': 0, '1': 1, '2': 2, '3+': 3}
loan_term_mapping = {'Corto Plazo (‚â§180 d√≠as)': 0, 'Medio Plazo (181-360 d√≠as)': 1, 'Largo Plazo (>360 d√≠as)': 2}

# Crear DataFrame con los valores de entrada
input_data = pd.DataFrame([[
    applicant_income, coapplicant_income, loan_amount, loan_term_mapping[loan_term], credit_history,
    gender, married, dependents, education, self_employed, property_area
]], columns=['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History',
             'Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area'])

# Hacer predicci√≥n con el modelo
if st.button("üìä Predecir Aprobaci√≥n"):
    prediction = model.predict(input_data)
    resultado = "‚úÖ Pr√©stamo Aprobado" if prediction[0] == 1 else "‚ùå Pr√©stamo No Aprobado"
    st.success(resultado)