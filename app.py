# -*- coding: utf-8 -*-
"""LOAN APPROVAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cGnknojN0S6kMRaoip1p-WDvAZvMnOl6

# **Selección de DataSet**

**Descripción del Dataset:** Este dataset con un tamaño de 10.000 filas y 14 columnas contiene información sobre clientes de una entidad financiera.

**Objetivo:** El problema de clasificación a resolver es predecir la variable "Exited" (1: el cliente se dió de baja, 0: el cliente permaneció). Esto permite a la empresa tomar decisiones basadas en el riesgo de pérdida de clientes.

**Variables:**

*   RowNumber: Índice de cada fila (irrelevante para el análisis).
*   CustomerId: Identificación única del cliente (también irrelevante para el análisis).
*   Surname: Apellido del cliente (irrelevante como predictor).
*   CreditScore: Puntaje de crédito del cliente (numérica).
*   Geography: País o región donde reside el cliente (categórica).
*   Gender: Género del cliente (categórica: "Male" o "Female").
*   Age: Edad del cliente (numérica).
*   Tenure: Tiempo de permanencia del cliente con la entidad, en años (numérica).
*   Balance: Saldo actual en la cuenta bancaria del cliente (numérica).
*   NumOfProducts: Número de productos contratados por el cliente (numérica).
*   HasCrCard: Indica si el cliente posee tarjeta de crédito (binaria: 1 o 0).
*   IsActiveMember: Indica si el cliente es un miembro activo (binaria: 1 o 0).
*   EstimatedSalary: Salario estimado del cliente (numérica).
*   Exited: Variable objetivo que indica si el cliente abandonó el servicio (binaria: 1 o 0).

#**0. Preparacion del Entorno**

**Descarga del dataset**
"""

import pandas as pd

def load_data():
    url = "https://raw.githubusercontent.com/dsrscientist/DSData/master/loan_prediction.csv"
    df = pd.read_csv(url)
    return df
df = load_data()

"""# **1. Analisis Exploratorio**

##**1.1. Mostramos en pantalla el dataframe (df)**
"""

df.head()

"""* Loan_ID: Identificador único para cada solicitud de préstamo. (Variable irrelevante para el modelo)
* Gender: Género del solicitante.
* Married: Estado civil del solicitante.
* Dependents: Número de personas a cargo del solicitante.
* Education: Nivel educativo del solicitante.
* Self_Employed: Indica si el solicitante trabaja por cuenta propia.
* ApplicantIncome: Ingreso mensual del solicitante en unidades monetarias.
* CoapplicantIncome: Ingreso mensual de un co-solicitante (por ejemplo, cónyuge).
* LoanAmount: Monto solicitado del préstamo en miles de unidades monetarias.
* Loan_Amount_Term: Duración del préstamo en días
* Credit_History: Registro crediticio del solicitante. (1 indica buen historial, 0 indica mal historial).
* Property_Area: Ubicación de la propiedad relacionada con el préstamo.
* Loan_Status: Variable objetivo del modelo.
"""

df = df.drop(columns= ['Loan_ID'])

# Convertimos 'Y' a 1 y 'N' a 0 en la variable objetivo Loan_Status
df['Loan_Status'] = df['Loan_Status'].map({'N': 0, 'Y': 1})

"""## **1.2. Valores nulos y Estadisticos descriptivos**"""

print("Tamaño df:\n", df.shape)

print("Columnas del df:\n", df.columns)

"""**Valores nulos**"""

# Mostramos por pantalla el tipo de dato por variable y cantidad de nulos
df.info()

"""Podemos ver que hay nulos en la mayoría de variables"""

df.isna().sum()

"""Dado que el dataset tiene 614 filas, la cantidad de valores nulos en algunas columnas no es excesiva. Por tanto, la cantidad de NaNs no justifica tratar los nulos en función de la moda/mediana según su rango de ingresos. Por lo que rellenar con moda o mediana global es la mejor opción para mantener el balance de los datos."""

df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)
df['Married'].fillna(df['Married'].mode()[0], inplace=True)
df['Dependents'].fillna(df['Dependents'].mode()[0], inplace=True)
df['Self_Employed'].fillna(df['Self_Employed'].mode()[0], inplace=True)
df['LoanAmount'].fillna(df['LoanAmount'].median(), inplace=True)
df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].median(), inplace=True)
df['Credit_History'].fillna(df['Credit_History'].mode()[0], inplace=True)

"""**Estadisticos descriptivos**"""

# Mostramos en pantalla los estadisticos descriptivos de las variables numericas
df[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']].describe()

"""Podemos hacer un analisis inicial sobre el conjunto con el que estamos trabajando:

* La media de ingresos del solicitante es 5403 y la del co-solicitante es 1621, lo que indica que en muchos casos el segundo ingreso es significativamente menor o incluso cero (percentil 25 de CoapplicantIncome es 0).
La desviación estándar es alta (6109 y 2926), lo que sugiere que los ingresos varían considerablemente entre los solicitantes.


* La media del préstamo es 146k, con una mediana de 128k, lo que indica una distribución sesgada hacia préstamos más grandes.
Hay una gran dispersión en los valores, con algunos préstamos alcanzando los 700k.

* La mediana de la duración del préstamo es 360 días, lo que sugiere que la mayoría de los préstamos se otorgan a largo plazo.

**Conclusiones iniciales:**

Hayn un riesgo de sesgo ya que, la gran variabilidad en los ingresos y cantidades de préstamos puede afectar la predicción del modelo si no se normalizan correctamente.

Luego, hay valores atípicos en los préstamos porque hay valores extremadamente grandes en comparación con la mediana, lo que podría afectar el desempeño del modelo.
"""

# Mostramos en pantalla los estadisticos descriptivos de las variables categoricas
df[['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area', 'Loan_Status']].describe()

"""El dataset tiene un sesgo hacia hombres, casados y graduados, lo que podría afectar el rendimiento del modelo si no se balancean los datos.

La tasa de aprobación es relativamente alta (68%), lo que podría significar que el modelo necesita más diferenciación entre aprobados y rechazados.

En conclusión, es posible que necesitemos aplicar técnicas de undersampling.

## **1.3. Analisis de Outliers**

**Histograma**
"""

#Importamos librerias
import matplotlib.pyplot as plt
import seaborn as sns

# Seleccionamos las columnas numéricas excluyendo las variables binarias
numerical_columns = [
    col for col in df.select_dtypes(include=['int64', 'float64'])
    if not (df[col].nunique() == 2 and sorted(df[col].unique()) == [0, 1])
]

# Graficamos histogramas de las variables
df[numerical_columns].hist(bins=20, figsize=(15, 12))
plt.suptitle('Histogramas de Variables Numéricas')
plt.show()

"""Tanto ApplicantIncome como CoapplicantIncome tienen una distribución altamente sesgada hacia la derecha.
La mayoría de los ingresos son bajos, pero hay algunos valores extremadamente altos (outliers).

En cuanto al LoanAmount, la distribución es sesgada a la derecha, indicando que la mayoría de los préstamos son pequeños o medianos, pero hay algunos valores extremadamente altos (outliers).

Esto indica que hay pocos solicitantes con ingresos muy altos que piden préstamos elevados, para que no afecte a la capacidad de generalizar del modelo vamos a reemplazar los valores extremos por el percentil 95.
Loan_Amount_Term (Plazo del Préstamo)

Por último, en cuanto al plazo del préstamo hay una elevada concentración en 360 días. Este sesgo podría hacer que el modelo aprenda patrones incorrectos si la variable no tiene suficiente variabilidad.
Una posible solución sería agruparlos en rangos para mejorar la representación de los valores más bajos (<180 días, 180-360 días, >360 días).
"""

import numpy as np
# Calculamos el percentil 95 para LoanAmount y ApplicantIncome
loan_amount_cap = df['LoanAmount'].quantile(0.90)
applicant_income_cap = df['ApplicantIncome'].quantile(0.90)
coapplicant_income_cap = df['CoapplicantIncome'].quantile(0.95)


# Reemplazamos los valores extremos
df['LoanAmount'] = np.where(df['LoanAmount'] > loan_amount_cap, loan_amount_cap, df['LoanAmount'])
df['ApplicantIncome'] = np.where(df['ApplicantIncome'] > applicant_income_cap, applicant_income_cap, df['ApplicantIncome'])
df['CoapplicantIncome'] = np.where(df['CoapplicantIncome'] > coapplicant_income_cap, coapplicant_income_cap, df['CoapplicantIncome'])

# Convertimos el plazo de préstamo a variable categórica
df['Loan_Amount_Term'] = df['Loan_Amount_Term'].apply(lambda x: 0 if x <= 180 else (1 if x <= 360 else 2))

"""**Graficos de barras (variables categoricas)**


"""

# Definimos las columnas categoricas
categorical_columns = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area', 'Loan_Amount_Term', 'Loan_Status']

# Creamos un subplot con estas columnas
fig, axes = plt.subplots(nrows=1, ncols=len(categorical_columns), figsize=(25, 5))

# Creamos un bucle con las columnas para asignarles ejes
for i, col in enumerate(categorical_columns):
    sns.countplot(x=df[col], ax=axes[i])
    axes[i].set_title(f"Distribution of {col}")
    axes[i].set_xlabel(col)
    axes[i].set_ylabel("Count")

plt.tight_layout()
plt.show()

"""* Género: La mayoría de los solicitantes son hombres, con una menor representación de mujeres (~112). Deberíamos evaluar si el género influye en la aprobación

* Estado civil: La mayoría de los solicitantes están casados. Puede estar relacionado con la percepción de estabilidad financiera.
Dependents (Número de Dependientes)

* Dependientes: Casi 360 personas no tienen personas a cargo. Un menor número de personas a cargo podría correlacionarse con una mayor capacidad de pago.

* Educación: Casi 480 personas tienen un título universitario, lo que puede estar relacionado con mejores ingresos y mayor tasa de aprobación de préstamos.

* Autónomos: La mayoría no son autónomos, lo que podría sugerir una mayor estabilidad financiera.

* Propiedad: Mayor concentración en zonas semiurbanas, seguidas de urbanas y rurales.



Estado préstamo: Alta tasa de aprobación. Si el dataset tiene más casos aprobados que rechazados, el modelo puede sesgarse hacia aprobar más préstamos.

**Conclusiones**

Por un lado, se observa un posible sesgo en género, estado civil y nivel educativo, lo que sugiere que la aprobación de préstamos puede estar influenciada por estos factores.

Por otro lado, la distribución de personas a cargo y trabajo autónomo sugiere que ciertos grupos pueden enfrentar más dificultades para obtener préstamos.

Podría ser útil analizar la correlación entre estas variables y la aprobación del préstamo, para determinar si el modelo debería balancear los datos o ajustar pesos.

**Boxplot**
"""

# Seleccionamos las columnas numéricas
numerical_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']

# Calculamos el número de filas y columnas necesarias para los subplots
num_cols = len(numerical_columns)
num_rows = (num_cols + 1) // 2  # Redondeamos hacia arriba para más de 2 columnas

# Crear subplots dinámicamente
fig, axes = plt.subplots(num_rows, 2, figsize=(12, num_rows * 5))  # 2 columnas por fila
axes = axes.flatten()  # Aplanamos para iterar fácilmente

# Dibujamos cada boxplot
for i, column in enumerate(numerical_columns):
    sns.boxplot(y=df[column], ax=axes[i])
    axes[i].set_title(f'Distribución de {column}')

# Ajustamos diseño y eliminamos ejes vacíos
for j in range(i + 1, len(axes)):
    axes[j].remove()

plt.tight_layout()
plt.show()

"""## **1.4. Matriz de corelaciones**"""

# Seleccionamos las columnas numéricas para la matriz de correlación
num_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']
corr_matrix = df[num_columns].corr()

# Visualizamos la matriz de correlación con un heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('Matriz de Correlación (Variables Numéricas)')
plt.show()

"""# **2. Transformamos las variables**

"""

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

X = df.drop('Loan_Status', axis=1)
y = df['Loan_Status']

numeric_features = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']
categorical_features = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area', 'Loan_Amount_Term']

# Transformamos las variables numéricas (imputación + escalado)
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

# Transformamos las variables categóricas nominales (One-Hot Encoding)
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', drop= 'first'))
])

# Combinamos transformadores en ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])
model_1 = Pipeline(steps=[('preprocessor', preprocessor),
                          ('classifier', LogisticRegression(random_state=42))
                        ])
model_2 = Pipeline(steps=[('preprocessor', preprocessor),
                          ('classifier', DecisionTreeClassifier(random_state=42))
                        ])
model_3 = Pipeline(steps=[('preprocessor', preprocessor),
                          ('classifier', RandomForestClassifier(random_state=42))
                        ])
model_4 = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', SVC(kernel='rbf', C=1, probability=True, random_state=42))
])

"""#**3. Modelo clasficación**

**Metodologia:**
Decidimos que testearemos multiples modelos de clasificacion para poder quedarnos con el mejor despues de evaluar las metricas de precision, accuracy y recall.

Dado el contexto económico actual, priorizamos la precisión en nuestro modelo de aprobación de préstamos para minimizar el riesgo de impago y garantizar la estabilidad financiera de la entidad.

Además, utilizaremos el metodo de undersampling de RandomUnderSampler para ver si podemos mejorar el rendimiento del modelo.
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

from sklearn.metrics import accuracy_score, classification_report

# Creamos diccionario de modelos
models = {
    "Logistic Regression": model_1,
    "Decision Tree": model_2,
    "Random Forest": model_3,
    "SVC": model_4,

}

# Entrenamos y predecimos en cada modelo
for name, model in models.items():
    print(f"\n modelo: {name}")

    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

# Evaluamos cada modelo
    print(f"Accuracy: {accuracy_score(y_test, y_pred):.2f}")
    print(f"\nClassification Report:\n{classification_report(y_test, y_pred)}")

"""###**UnderSampling**"""

# Importamos la librería RandomUnderSampler
from imblearn.under_sampling import RandomUnderSampler

# Aplicamos undersampling sobre el conjunto de entrenamiento
rus = RandomUnderSampler(sampling_strategy=0.5, random_state=42)
X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)

#Verificamos que se ha hecho el undersampling correctamente
print("Distribución después de undersampling:")
print(pd.Series(y_train_resampled).value_counts())

# Entrenamos y predecimos en cada modelo
for name, model in models.items():
    print(f"\nEntrenando modelo: {name}")

    model.fit(X_train_resampled, y_train_resampled)

    y_pred = model.predict(X_test)

# Evaluamos cada modelo
    print(f"Accuracy: {accuracy_score(y_test, y_pred):.2f}")
    print(f"\nClassification Report:\n{classification_report(y_test, y_pred)}")

"""Dado que nuestro objetivo es minimizar impagos y reducir la concesión de préstamos a clientes de alto riesgo, el modelo de regresión logística es el que mejor rendimiento obtiene.

* Maximiza la precisión en clientes solventes, asegurando que las aprobaciones sean más seguras.
* Reduce la probabilidad de conceder préstamos a clientes que no pueden pagar (menor tasa de falsos positivos).
* Mantiene un recall alto, lo que significa que no estamos rechazando demasiados clientes solventes.

Por tanto, El modelo de LR es el más adecuado para una entidad financiera que prioriza precisión y busca una cartera de préstamos más segura y estable.

##**4. Streamlit**
"""

#pip install streamlit

import pickle

# Guardar el modelo entrenado
with open("model.pkl", "wb") as f:
    pickle.dump(model_4, f)

import streamlit as st
import pandas as pd
import pickle

# Cargar el modelo entrenado
with open("model.pkl", "rb") as f:
    model = pickle.load(f)

# Configuración de la app
st.title("🏦 Loan Approval Prediction App")
st.write("Completa los detalles para predecir si el préstamo será aprobado.")

# Entrada de datos por el usuario
gender = st.selectbox("Género", ['Male', 'Female'])
married = st.selectbox("Casado", ['No', 'Yes'])
dependents = st.selectbox("Número de personas a cargo", ['0', '1', '2', '3+'])
education = st.selectbox("Educación", ['Not Graduate', 'Graduate'])
self_employed = st.selectbox("Trabaja por cuenta propia", ['No', 'Yes'])
applicant_income = st.number_input("Ingreso del Solicitante", min_value=0, step=100)
coapplicant_income = st.number_input("Ingreso del Co-Solicitante", min_value=0, step=100)
loan_amount = st.number_input("Cantidad del Préstamo", min_value=0, step=10)
loan_term = st.selectbox("Plazo del Préstamo", ['Corto Plazo (≤180 días)', 'Medio Plazo (181-360 días)', 'Largo Plazo (>360 días)'])
property_area = st.selectbox("Propiedad", ['Urban', 'Rural', 'Semiurban'])
# Modificar la selección para que se entiendan las opciones de credit_history
credit_history = st.selectbox("Historial de Crédito", ['Buen historial', 'Mal historial'])
# Mapeo para que el modelo reciba 1 y 0 en vez de los textos
credit_history_mapping = {'Buen historial': 1.0, 'Mal historial': 0.0}
credit_history = credit_history_mapping[credit_history]


# Mapeo de valores para que coincidan con los datos originales
dependents_mapping = {'0': 0, '1': 1, '2': 2, '3+': 3}
loan_term_mapping = {'Corto Plazo (≤180 días)': 0, 'Medio Plazo (181-360 días)': 1, 'Largo Plazo (>360 días)': 2}

# Crear DataFrame con los valores de entrada
input_data = pd.DataFrame([[
    applicant_income, coapplicant_income, loan_amount, loan_term_mapping[loan_term], credit_history,
    gender, married, dependents, education, self_employed, property_area
]], columns=['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History',
             'Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area'])

# Hacer predicción con el modelo
if st.button("📊 Predecir Aprobación"):
    prediction = model.predict(input_data)
    resultado = "✅ Préstamo Aprobado" if prediction[0] == 1 else "❌ Préstamo No Aprobado"
    st.success(resultado)